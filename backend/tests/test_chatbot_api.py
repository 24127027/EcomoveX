import sys
from pathlib import Path
import asyncio
import os

# Load .env t·ª´ backend
from dotenv import load_dotenv
env_path = Path(__file__).resolve().parent.parent / ".env"
load_dotenv(env_path)

backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

import asyncio
import os

async def test_real_llm_api():
    """Test real LLM API integration (requires API key)"""
    print("\n" + "="*60)
    print("üß™ TESTING REAL LLM API INTEGRATION")
    print("="*60 + "\n")
    
    # Check if API key exists
    api_key = os.getenv("OPEN_ROUTER_API_KEY")
    if not api_key:
        print("‚ö†Ô∏è  OPEN_ROUTER_API_KEY not found in environment")
        print("   Set it with: set OPEN_ROUTER_API_KEY=your_key_here")
        print("   Skipping real API tests\n")
        return
    
    print(f"‚úÖ API Key found: {api_key[:10]}...{api_key[-4:]}\n")
    
    # Test 1: Simple conversation
    print("üìã Test 1: Simple Conversation")
    try:
        from services.chatbot.llm_service import LLMService
        
        llm = LLMService()
        
        messages = [
            {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω du l·ªãch th√¥ng minh c·ªßa EcomoveX."},
            {"role": "user", "content": "Xin ch√†o! T√¥i mu·ªën ƒëi du l·ªãch ƒê√† N·∫µng."}
        ]
        
        print("  Sending request to LLM...")
        reply = await llm.generate_reply(messages)
        
        print(f"  ‚úÖ Response received")
        print(f"     User: Xin ch√†o! T√¥i mu·ªën ƒëi du l·ªãch ƒê√† N·∫µng.")
        print(f"     Bot: {reply}\n")
        
    except Exception as e:
        print(f"  ‚ùå Simple conversation test failed: {e}\n")
        import traceback
        traceback.print_exc()
    
    # Test 2: Multi-turn conversation
    print("üìã Test 2: Multi-turn Conversation")
    try:
        from services.chatbot.llm_service import LLMService
        
        llm = LLMService()
        
        conversation = [
            {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω du l·ªãch EcomoveX, chuy√™n v·ªÅ du l·ªãch sinh th√°i."},
            {"role": "user", "content": "T√¥i c√≥ ng√¢n s√°ch 5 tri·ªáu cho 3 ng√†y ·ªü ƒê√† N·∫µng"},
        ]
        
        print("  Turn 1:")
        reply1 = await llm.generate_reply(conversation)
        print(f"    User: T√¥i c√≥ ng√¢n s√°ch 5 tri·ªáu cho 3 ng√†y ·ªü ƒê√† N·∫µng")
        print(f"    Bot: {reply1[:100]}...")
        
        conversation.append({"role": "assistant", "content": reply1})
        conversation.append({"role": "user", "content": "G·ª£i √Ω cho t√¥i ƒë·ªãa ƒëi·ªÉm th√¢n thi·ªán v·ªõi m√¥i tr∆∞·ªùng"})
        
        print("  Turn 2:")
        reply2 = await llm.generate_reply(conversation)
        print(f"    User: G·ª£i √Ω cho t√¥i ƒë·ªãa ƒëi·ªÉm th√¢n thi·ªán v·ªõi m√¥i tr∆∞·ªùng")
        print(f"    Bot: {reply2[:100]}...\n")
        
    except Exception as e:
        print(f"  ‚ùå Multi-turn test failed: {e}\n")
        import traceback
        traceback.print_exc()
    
    # Test 3: Planning assistance
    print("üìã Test 3: Planning Assistance")
    try:
        from services.chatbot.llm_service import LLMService
        
        llm = LLMService()
        
        messages = [
            {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω l·∫≠p k·∫ø ho·∫°ch du l·ªãch. Gi√∫p ng∆∞·ªùi d√πng t·ªï ch·ª©c l·ªãch tr√¨nh chi ti·∫øt."},
            {"role": "user", "content": "L·∫≠p k·∫ø ho·∫°ch chi ti·∫øt cho 1 ng√†y ·ªü H·ªôi An, b·∫Øt ƒë·∫ßu t·ª´ 8h s√°ng"}
        ]
        
        print("  Requesting detailed itinerary...")
        reply = await llm.generate_reply(messages)
        
        print(f"  ‚úÖ Itinerary received")
        print(f"     Request: L·∫≠p k·∫ø ho·∫°ch chi ti·∫øt cho 1 ng√†y ·ªü H·ªôi An")
        print(f"     Response:\n{reply}\n")
        
    except Exception as e:
        print(f"  ‚ùå Planning assistance test failed: {e}\n")
        import traceback
        traceback.print_exc()
    
    print("="*60)
    print("‚úÖ REAL API TESTS COMPLETED")
    print("="*60 + "\n")

if __name__ == "__main__":
    # Check for API key first
    if os.getenv("OPEN_ROUTER_API_KEY"):
        asyncio.run(test_real_llm_api())
    else:
        print("File path:", __file__)
        print("ENV path:", env_path)
        print("ENV exists?", env_path.exists())

        print("[DEBUG] API KEY =", os.getenv("OPEN_ROUTER_API_KEY"))
        print("\n‚ö†Ô∏è  Set OPEN_ROUTER_API_KEY environment variable to run real API tests")
        print("   Example: set OPEN_ROUTER_API_KEY=your_key_here\n")